import { Injectable, Logger } from '@nestjs/common';
import { PrismaService } from '../common/database/prisma.service';
import { S3Service } from '../common/s3/s3.service';
import { QueueService } from '../common/queue/queue.service';
import Parser from 'tree-sitter';

@Injectable()
export class ParserWorker {
  private readonly logger = new Logger(ParserWorker.name);
  private parser: Parser | null = null;

  constructor(
    private readonly prisma: PrismaService,
    private readonly s3: S3Service,
    private readonly queue: QueueService
  ) {}

  async process(job: any) {
    const { repoId, sha, path, blobSha } = job.data;

    this.logger.log(`Parsing ${path} for repo ${repoId}`);

    try {
      // Get file content from S3
      const fileBlob = await this.prisma.fileBlob.findFirst({
        where: { repoId, sha: blobSha },
      });

      if (!fileBlob) {
        throw new Error(`FileBlob not found: ${blobSha}`);
      }

      const content = await this.s3.getFileContent(fileBlob.s3Key);

      // Parse with tree-sitter
      const language = this.detectLanguage(path);
      const ast = await this.parseTree(content, language);

      if (!ast) {
        this.logger.warn(`Failed to parse ${path}`);
        return;
      }

      // Store AST in S3
      const astS3Key = await this.s3.storeAST(repoId, sha, path, ast);

      // Extract nodes
      const nodes = this.extractNodes(ast, path, content);

      // Update file blob
      await this.prisma.fileBlob.update({
        where: { id: fileBlob.id },
        data: { parsedAt: new Date() },
      });

      // Create Node records and enqueue embeddings
      for (const nodeData of nodes) {
        // Create or update Node record
        const node = await this.prisma.node.upsert({
          where: {
            repoId_filePath_nodePath_blobSha: {
              repoId,
              filePath: path,
              nodePath: nodeData.path,
              blobSha,
            },
          },
          create: {
            repoId,
            filePath: path,
            blobSha,
            nodePath: nodeData.path,
            nodeType: nodeData.type || 'export',
            startLine: nodeData.startLine || 1,
            endLine: nodeData.endLine || 1,
            text: nodeData.text,
            summary: null, // Will be generated by embedding worker
          },
          update: {
            text: nodeData.text,
            updatedAt: new Date(),
          },
        });

        // Enqueue embedding job with nodeId
        await this.queue.enqueue('embed-chunks', {
          repoId,
          sha,
          path,
          nodePath: nodeData.path,
          nodeText: nodeData.text,
          astS3Key,
          nodeId: node.id,
        });
      }
    } catch (error) {
      this.logger.error(`Failed to parse ${path}:`, error);
      throw error;
    }
  }

  private async parseTree(content: string, language: string): Promise<any> {
    // TODO: Load tree-sitter parser for language
    // This requires pre-built wasm parsers
    // For now, return mock structure
    return {
      rootNode: {
        type: 'source_file',
        text: content.substring(0, 100),
      },
    };
  }

  private extractNodes(
    ast: any,
    filePath: string,
    content: string,
  ): Array<{
    path: string;
    text: string;
    type?: string;
    startLine?: number;
    endLine?: number;
  }> {
    const nodes: Array<{
      path: string;
      text: string;
      type?: string;
      startLine?: number;
      endLine?: number;
    }> = [];

    // Extract functions, classes, exports, etc.
    // This is a simplified version - production code would traverse AST properly
    // For now, create a root node and try to extract basic structures
    const lines = content.split('\n');
    nodes.push({
      path: `${filePath}/root`,
      text: content.substring(0, 5000), // Limit text size
      type: 'source_file',
      startLine: 1,
      endLine: Math.min(lines.length, 100),
    });

    // Try to extract function-like patterns (basic regex for now)
    const functionPattern = /(?:function|const|let|var)\s+(\w+)\s*[=\(]/g;
    let match;
    let functionCount = 0;
    while ((match = functionPattern.exec(content)) !== null && functionCount < 10) {
      const funcName = match[1];
      const startPos = match.index;
      const startLine = content.substring(0, startPos).split('\n').length;
      
      // Find end of function (simplified - find matching brace)
      let braceCount = 0;
      let inFunction = false;
      let endPos = startPos;
      
      for (let i = startPos; i < Math.min(startPos + 2000, content.length); i++) {
        if (content[i] === '{') {
          braceCount++;
          inFunction = true;
        } else if (content[i] === '}') {
          braceCount--;
          if (inFunction && braceCount === 0) {
            endPos = i + 1;
            break;
          }
        }
      }
      
      const endLine = content.substring(0, endPos).split('\n').length;
      const funcText = content.substring(startPos, endPos);
      
      if (funcText.length > 50 && funcText.length < 5000) {
        nodes.push({
          path: `${filePath}/function.${funcName}`,
          text: funcText,
          type: 'function',
          startLine,
          endLine,
        });
        functionCount++;
      }
    }

    return nodes;
  }

  private detectLanguage(path: string): string {
    const ext = path.split('.').pop()?.toLowerCase() || '';
    const langMap: Record<string, string> = {
      js: 'javascript',
      ts: 'typescript',
      py: 'python',
      java: 'java',
      go: 'go',
      rs: 'rust',
    };
    return langMap[ext] || 'javascript';
  }
}
